{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQGGnQA0_Xav",
        "outputId": "92097c94-5063-429b-9f4a-4c5050d9c118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from '/content/out_dataset_pertanyaan_jawaban.csv'...\n",
            "Initial dataset size: 16 rows\n",
            "After dropping missing/empty rows: 16 rows\n",
            "After removing duplicates: 16 rows\n",
            "Vectorizing text data...\n",
            "Training Naive Bayes classifier...\n",
            "Saving model to 'naive_bayes_model.pkl' and vectorizer to 'vectorizer.pkl'...\n",
            "Training complete and files saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import joblib\n",
        "\n",
        "def load_and_clean_data(csv_path):\n",
        "    \"\"\"\n",
        "    Load CSV dataset with flexible parsing and clean it:\n",
        "    - Remove rows with missing or empty 'pertanyaan' or 'jawaban'\n",
        "    - Strip whitespace and lowercase 'pertanyaan'\n",
        "    - Remove duplicates\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(csv_path):\n",
        "        raise FileNotFoundError(f\"CSV file '{csv_path}' not found.\")\n",
        "\n",
        "    print(f\"Loading dataset from '{csv_path}'...\")\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, engine='python', encoding='utf-8', quotechar='\"')\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Failed to read CSV file: {e}\")\n",
        "\n",
        "    required_columns = {'pertanyaan', 'jawaban'}\n",
        "    if not required_columns.issubset(df.columns):\n",
        "        raise ValueError(f\"CSV must contain columns {required_columns}. Found columns: {df.columns}\")\n",
        "\n",
        "    print(f\"Initial dataset size: {len(df)} rows\")\n",
        "\n",
        "    # Drop rows with missing or empty 'pertanyaan' or 'jawaban'\n",
        "    df = df.dropna(subset=['pertanyaan', 'jawaban'])\n",
        "    df = df[df['pertanyaan'].str.strip() != '']\n",
        "    df = df[df['jawaban'].str.strip() != '']\n",
        "    print(f\"After dropping missing/empty rows: {len(df)} rows\")\n",
        "\n",
        "    # Strip whitespace and lowercase 'pertanyaan'\n",
        "    df['pertanyaan'] = df['pertanyaan'].str.strip().str.lower()\n",
        "    df['jawaban'] = df['jawaban'].str.strip()\n",
        "\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"After removing duplicates: {len(df)} rows\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def train_and_save_model(df, model_path='naive_bayes_model.pkl', vectorizer_path='vectorizer.pkl'):\n",
        "    \"\"\"\n",
        "    Train a Multinomial Naive Bayes model on the cleaned dataset and save the model and vectorizer.\n",
        "    \"\"\"\n",
        "    X = df['pertanyaan'].astype(str)\n",
        "    y = df['jawaban'].astype(str)\n",
        "\n",
        "    print(\"Vectorizing text data...\")\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "    print(\"Training Naive Bayes classifier...\")\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_vec, y)\n",
        "\n",
        "    print(f\"Saving model to '{model_path}' and vectorizer to '{vectorizer_path}'...\")\n",
        "    joblib.dump(model, model_path)\n",
        "    joblib.dump(vectorizer, vectorizer_path)\n",
        "\n",
        "    print(\"Training complete and files saved.\")\n",
        "\n",
        "def main():\n",
        "    # Adjust this path to your CSV file location\n",
        "    csv_filename = '/content/out_dataset_pertanyaan_jawaban.csv'\n",
        "\n",
        "    # Load and clean data\n",
        "    df_cleaned = load_and_clean_data(csv_filename)\n",
        "\n",
        "    # Train model and save artifacts\n",
        "    train_and_save_model(df_cleaned)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "\n",
        "# Define the filenames for the saved model and vectorizer\n",
        "model_path = 'naive_bayes_model.pkl'\n",
        "vectorizer_path = 'vectorizer.pkl'\n",
        "\n",
        "# Check if the model and vectorizer files exist\n",
        "if not os.path.isfile(model_path):\n",
        "    raise FileNotFoundError(f\"Model file '{model_path}' not found. Please train and save the model first.\")\n",
        "if not os.path.isfile(vectorizer_path):\n",
        "    raise FileNotFoundError(f\"Vectorizer file '{vectorizer_path}' not found. Please train and save the vectorizer first.\")\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load(model_path)\n",
        "vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "def predict_answer(question):\n",
        "    \"\"\"\n",
        "    Predict the answer for a given question using the loaded Naive Bayes model.\n",
        "\n",
        "    Parameters:\n",
        "    - question (str): The input question text.\n",
        "\n",
        "    Returns:\n",
        "    - str: The predicted answer.\n",
        "    \"\"\"\n",
        "    # Transform the input question using the loaded vectorizer\n",
        "    question_vec = vectorizer.transform([question])\n",
        "    # Predict the answer using the loaded model\n",
        "    predicted_answer = model.predict(question_vec)\n",
        "    return predicted_answer[0]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    sample_question = \"halo\"\n",
        "    predicted = predict_answer(sample_question)\n",
        "    print(f\"Question: {sample_question}\")\n",
        "    print(f\"Predicted Answer: {predicted}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyZX3O-O_2by",
        "outputId": "afd3542c-1fb1-47aa-8c10-55909bcb53fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: halo\n",
            "Predicted Answer: Berikut pilihan kost dalam rentang harga tersebut:\n",
            "• Kost Mawar — Rp1.000.000/bulan (AC, Kamar Mandi Dalam)\n",
            "• Kost Melati — Rp1.200.000/bulan (AC, WiFi, Parkir Motor)\n",
            "• Kost Anggrek — Rp1.500.000/bulan (Lengkap, Dapur Bersama)\n"
          ]
        }
      ]
    }
  ]
}